{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e36ac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\anaconda3-202205\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\anaconda3-202205\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: numpy>=1.18.5 in c:\\anaconda3-202205\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda3-202205\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda3-202205\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\anaconda3-202205\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\anaconda3-202205\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\anaconda3-202205\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\anaconda3-202205\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.6.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\anaconda3-202205\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\anaconda3-202205\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\anaconda3-202205\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\anaconda3-202205\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\anaconda3-202205\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\anaconda3-202205\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\anaconda3-202205\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda3-202205\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3-202205\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3-202205\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3-202205\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\anaconda3-202205\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.2.0)\n",
      "Installing collected packages: tensorflow-io-gcs-filesystem, libclang\n",
      "Successfully installed libclang-16.0.0 tensorflow-io-gcs-filesystem-0.31.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76477b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Arerê</td>\n",
       "      <td>/ivete-sangalo/arere.html</td>\n",
       "      <td>Tudo o que eu quero nessa vida,\\nToda vida, é\\...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Se Eu Não Te Amasse Tanto Assim</td>\n",
       "      <td>/ivete-sangalo/se-eu-nao-te-amasse-tanto-assim...</td>\n",
       "      <td>Meu coração\\nSem direção\\nVoando só por voar\\n...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Céu da Boca</td>\n",
       "      <td>/ivete-sangalo/chupa-toda.html</td>\n",
       "      <td>É de babaixá!\\nÉ de balacubaca!\\nÉ de babaixá!...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Quando A Chuva Passar</td>\n",
       "      <td>/ivete-sangalo/quando-a-chuva-passar.html</td>\n",
       "      <td>Quando a chuva passar\\n\\nPra quê falar\\nSe voc...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Sorte Grande</td>\n",
       "      <td>/ivete-sangalo/sorte-grande.html</td>\n",
       "      <td>A minha sorte grande foi você cair do céu\\nMin...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ALink                            SName  \\\n",
       "0  /ivete-sangalo/                            Arerê   \n",
       "1  /ivete-sangalo/  Se Eu Não Te Amasse Tanto Assim   \n",
       "2  /ivete-sangalo/                      Céu da Boca   \n",
       "3  /ivete-sangalo/            Quando A Chuva Passar   \n",
       "4  /ivete-sangalo/                     Sorte Grande   \n",
       "\n",
       "                                               SLink  \\\n",
       "0                          /ivete-sangalo/arere.html   \n",
       "1  /ivete-sangalo/se-eu-nao-te-amasse-tanto-assim...   \n",
       "2                     /ivete-sangalo/chupa-toda.html   \n",
       "3          /ivete-sangalo/quando-a-chuva-passar.html   \n",
       "4                   /ivete-sangalo/sorte-grande.html   \n",
       "\n",
       "                                               Lyric language  \n",
       "0  Tudo o que eu quero nessa vida,\\nToda vida, é\\...       pt  \n",
       "1  Meu coração\\nSem direção\\nVoando só por voar\\n...       pt  \n",
       "2  É de babaixá!\\nÉ de balacubaca!\\nÉ de babaixá!...       pt  \n",
       "3  Quando a chuva passar\\n\\nPra quê falar\\nSe voc...       pt  \n",
       "4  A minha sorte grande foi você cair do céu\\nMin...       pt  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding\n",
    "\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "df = pd.read_csv(\"./lyrics-data.csv\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pdf = pd.read_csv('./data/PoetryFoundationData.csv',quotechar='\"')\n",
    "\n",
    "#pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(x):\n",
    "\n",
    "   text = x['Lyric']\n",
    "\n",
    "    \n",
    "   sections = str(text).split()\n",
    "\n",
    "   keys = {'Verse 1': np.nan,'Verse 2':np.nan,'Verse 3':np.nan,'Verse 4':np.nan, 'Chorus':np.nan}\n",
    "\n",
    "   lyrics = str()\n",
    "\n",
    "   single_text = []\n",
    "\n",
    "   res = {}\n",
    "\n",
    "   for s in sections:\n",
    "\n",
    "       key = s[s.find('[') + 1:s.find(']')].strip()\n",
    "\n",
    "       if ':' in key:\n",
    "\n",
    "           key = key[:key.find(':')]\n",
    "          \n",
    "\n",
    "       if key in keys:\n",
    "\n",
    "           single_text += [x.lower().replace('(','').replace(')','').translate(translator) for x in s[s.find(']')+1:].split('\\\\n') if len(x) > 1]\n",
    "          \n",
    "\n",
    "       res['single_text'] =  ' \\n '.join(single_text)\n",
    "\n",
    "   return pd.Series(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57f04367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Arerê</td>\n",
       "      <td>/ivete-sangalo/arere.html</td>\n",
       "      <td>Tudo o que eu quero nessa vida,\\nToda vida, é\\...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Se Eu Não Te Amasse Tanto Assim</td>\n",
       "      <td>/ivete-sangalo/se-eu-nao-te-amasse-tanto-assim...</td>\n",
       "      <td>Meu coração\\nSem direção\\nVoando só por voar\\n...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Céu da Boca</td>\n",
       "      <td>/ivete-sangalo/chupa-toda.html</td>\n",
       "      <td>É de babaixá!\\nÉ de balacubaca!\\nÉ de babaixá!...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Quando A Chuva Passar</td>\n",
       "      <td>/ivete-sangalo/quando-a-chuva-passar.html</td>\n",
       "      <td>Quando a chuva passar\\n\\nPra quê falar\\nSe voc...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Sorte Grande</td>\n",
       "      <td>/ivete-sangalo/sorte-grande.html</td>\n",
       "      <td>A minha sorte grande foi você cair do céu\\nMin...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ALink                            SName  \\\n",
       "0  /ivete-sangalo/                            Arerê   \n",
       "1  /ivete-sangalo/  Se Eu Não Te Amasse Tanto Assim   \n",
       "2  /ivete-sangalo/                      Céu da Boca   \n",
       "3  /ivete-sangalo/            Quando A Chuva Passar   \n",
       "4  /ivete-sangalo/                     Sorte Grande   \n",
       "\n",
       "                                               SLink  \\\n",
       "0                          /ivete-sangalo/arere.html   \n",
       "1  /ivete-sangalo/se-eu-nao-te-amasse-tanto-assim...   \n",
       "2                     /ivete-sangalo/chupa-toda.html   \n",
       "3          /ivete-sangalo/quando-a-chuva-passar.html   \n",
       "4                   /ivete-sangalo/sorte-grande.html   \n",
       "\n",
       "                                               Lyric language  \n",
       "0  Tudo o que eu quero nessa vida,\\nToda vida, é\\...       pt  \n",
       "1  Meu coração\\nSem direção\\nVoando só por voar\\n...       pt  \n",
       "2  É de babaixá!\\nÉ de balacubaca!\\nÉ de babaixá!...       pt  \n",
       "3  Quando a chuva passar\\n\\nPra quê falar\\nSe voc...       pt  \n",
       "4  A minha sorte grande foi você cair do céu\\nMin...       pt  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./lyrics-data.csv\")\n",
    "#df = df.join( df.apply(split_text, axis=1))\n",
    "#sum_df = pd.DataFrame( df['single_text'] )\n",
    "\n",
    "\n",
    "\n",
    "sum_df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e9c61ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'single_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'single_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sum_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame( \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msingle_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m )\n\u001b[0;32m      2\u001b[0m sum_df\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'single_text'"
     ]
    }
   ],
   "source": [
    "sum_df = pd.DataFrame( df['single_text'] )\n",
    "sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239dfa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07b42ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "568f8d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Total words:  193\n",
      "['2x', '2x', '2x', '2x', 'chorus50', 'chorus1', 'chorus2', 'chorus3', 'chorus4', 'x2', 'chorus2x', 'chorus4x', '2x', 'x4', 'chorus2x', 'chorus2x', 'chorus2x', 'chorusif', 'x2', 'chorusbaby', 'chorusjazze', 'x2', 'x2', 'x2', '2x', 'chorus2', 'how', 'how', 'repeated', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'x2', 'chorus2x', 'chorusbut', 'chorusyoyoyoyon', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'chorus…', 'chorusthe', 'chorusthe', 'chorusthe', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'chorusand', 'choruswomen', 'choruswomen', 'chorus2x', 'chorusbobby', 'ja', 'chorustweet', '2x', 'flo', 'flo', 'flo', 'flo', 'x2', 'nate', 'nate', 'nate', 'chorusjd', '50', '50', '50', '50', '50', 'chorus50', '50', 'x4', '2xti', 'choruskanye', 'choruswyclef', 'choruswyclef', 'eminem', 'eminem', 'eminem', 'eminem', 'chorusall', 'chorusall', 'chorusall', 'chorus4x', 'chorus…', 'chorus…', 'chorus…', 'chorus…', 'chorus…', 'chorus…', 'chorus…', 'chorus…', 'chorus…', 'chorus…', 'chorus…', 'chorus…', 'let', 'shes', 'chorusits', 'chorusits', 'chorusits', 'chorusthis', 'chorus2x', '2xsbackground', 'i', 'i', 'i', 'i', 'ichorus', 'ichorus', 'i', 'i', 'ichorus', 'i', 'i', 'i', 'i', 'i', 'x2', 'chorusgirl', 'chorus1', 'chorus1x', 'chorus1x', 'chorusx2', 'chorusx2', 'chorusx2', 'chorusx2', '2x', 'chorusdmx', 'dmx', 'chorus50lil', 'chorustboz', 'chorus2x', 'chorus4x', '12x', '12x', 'chorus4x', 'chorus4x', 'chorusrepeat', 'kandi', 'chorusfredro', 'chorusmaster', 'x8', 'x8', 'x8', 'chorusmaster', 'chorus2x', 'chorus2x', 'chorus2x', 'africa', 'chorus3', 'chorus2x', 'i', 'i', 'i', 'chorussurrender', 'i', 'i', 'i']\n",
      "Words with less than 2 appearances: 28\n",
      "Words with more than 2 appearances: 27\n",
      "Valid sequences of size 5: 89\n",
      "[['flo', 'flo', 'flo', 'flo', 'x2'], ['2x', '2x', '2x', '2x', 'chorus50'], ['chorus4x', 'chorus…', 'chorus…', 'chorus…', 'chorus…']]\n"
     ]
    }
   ],
   "source": [
    "text_as_list = []\n",
    "\n",
    "frequencies = {}\n",
    "\n",
    "uncommon_words = set()\n",
    "\n",
    "MIN_FREQUENCY = 2\n",
    "\n",
    "MIN_SEQ = 5\n",
    "\n",
    "BATCH_SIZE =  32\n",
    "\n",
    "print(\"Starting\")\n",
    "\n",
    "\n",
    "def extract_text(text):\n",
    "\n",
    "   global text_as_list\n",
    "\n",
    "   text_as_list += [w for w in text.split(' ') if w.strip() != '' and w != '\\n' and w != 'chorus']\n",
    "\n",
    "\n",
    "\n",
    "sum_df['single_text'].apply( extract_text )\n",
    "\n",
    "print('Total words: ', len(text_as_list))\n",
    "\n",
    "print(text_as_list)\n",
    "for w in text_as_list:\n",
    "\n",
    "   frequencies[w] = frequencies.get(w, 0) + 1\n",
    "  \n",
    "\n",
    "uncommon_words = set([key for key in frequencies.keys() if frequencies[key] < MIN_FREQUENCY])\n",
    "\n",
    "words = sorted(set([key for key in frequencies.keys() if frequencies[key] >= MIN_FREQUENCY]))\n",
    "\n",
    "\n",
    "num_words = len(words)\n",
    "\n",
    "word_indices = dict((w, i) for i, w in enumerate(words))\n",
    "\n",
    "indices_word = dict((i, w) for i, w in enumerate(words))\n",
    "\n",
    "print('Words with less than {} appearances: {}'.format( MIN_FREQUENCY, len(uncommon_words)))\n",
    "\n",
    "print('Words with more than {} appearances: {}'.format( MIN_FREQUENCY, len(words)))\n",
    "\n",
    "\n",
    "valid_seqs = []\n",
    "\n",
    "end_seq_words = []\n",
    "\n",
    "for i in range(len(text_as_list) - MIN_SEQ ):\n",
    "\n",
    "   end_slice = i + MIN_SEQ + 1\n",
    "\n",
    "   if len( set(text_as_list[i:end_slice]).intersection(uncommon_words) ) == 0:\n",
    "\n",
    "       valid_seqs.append(text_as_list[i: i + MIN_SEQ])\n",
    "\n",
    "       end_seq_words.append(text_as_list[i + MIN_SEQ])\n",
    "      \n",
    "\n",
    "print('Valid sequences of size {}: {}'.format(MIN_SEQ, len(valid_seqs)))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(valid_seqs, end_seq_words, test_size=0.02, random_state=42)\n",
    "\n",
    "print(X_train[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76c5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator for fit and evaluate\n",
    "\n",
    "def generator(sentence_list, next_word_list, batch_size):\n",
    "\n",
    "   index = 0\n",
    "\n",
    "   while True:\n",
    "\n",
    "       x = np.zeros((batch_size, MIN_SEQ), dtype=np.int32)\n",
    "\n",
    "       y = np.zeros((batch_size), dtype=np.int32)\n",
    "\n",
    "       for i in range(batch_size):\n",
    "\n",
    "           for t, w in enumerate(sentence_list[index % len(sentence_list)]):\n",
    "\n",
    "               x[i, t] = word_indices[w]\n",
    "\n",
    "           y[i] = word_indices[next_word_list[index % len(sentence_list)]]\n",
    "\n",
    "           index = index + 1\n",
    "\n",
    "       yield x, y\n",
    "\n",
    "\n",
    "# Functions from keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "\n",
    "   # helper function to sample an index from a probability array\n",
    "\n",
    "   preds = np.asarray(preds).astype('float64')\n",
    "\n",
    "   preds = np.log(preds) / temperature\n",
    "\n",
    "   exp_preds = np.exp(preds)\n",
    "\n",
    "   preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "   probas = np.random.multinomial(1, preds, 1)\n",
    "\n",
    "   return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "\n",
    "   # Function invoked at end of each epoch. Prints generated text.\n",
    "\n",
    "   examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n",
    "\n",
    "\n",
    "   # Randomly pick a seed sequence\n",
    "\n",
    "   seed_index = np.random.randint(len(X_train+X_test))\n",
    "\n",
    "   seed = (X_train+X_test)[seed_index]\n",
    "\n",
    "\n",
    "   for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "\n",
    "       sentence = seed\n",
    "\n",
    "       examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n",
    "\n",
    "       examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n",
    "\n",
    "       examples_file.write(' '.join(sentence))\n",
    "\n",
    "\n",
    "       for i in range(50):\n",
    "\n",
    "           x_pred = np.zeros((1, MIN_SEQ))\n",
    "\n",
    "           for t, word in enumerate(sentence):\n",
    "\n",
    "               x_pred[0, t] = word_indices[word]\n",
    "\n",
    "\n",
    "           preds = model.predict(x_pred, verbose=0)[0]\n",
    "\n",
    "           next_index = sample(preds, diversity)\n",
    "\n",
    "           next_word = indices_word[next_index]\n",
    "\n",
    "\n",
    "           sentence = sentence[1:]\n",
    "\n",
    "           sentence.append(next_word)\n",
    "\n",
    "\n",
    "           examples_file.write(\" \"+next_word)\n",
    "\n",
    "       examples_file.write('\\n')\n",
    "\n",
    "   examples_file.write('='*80 + '\\n')\n",
    "\n",
    "   examples_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f655761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "\n",
    "   print('Build model...')\n",
    "\n",
    "   model = Sequential()\n",
    "\n",
    "   model.add(Embedding(input_dim=len(words), output_dim=1024))\n",
    "\n",
    "   model.add(Bidirectional(LSTM(128)))\n",
    "\n",
    "   model.add(Dense(len(words)))\n",
    "\n",
    "   model.add(Activation('softmax'))\n",
    "\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "339172d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Epoch 1/20\n",
      "441/443 [============================>.] - ETA: 0s - loss: 0.5258 - accuracy: 0.7284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/KOLLENBE/Desktop/models\\001-words%d-sequence%d-minfreq%d-loss0.5259-acc0.7285-val_loss0.9796-val_acc0.6091(len(words), MIN_SEQ, MIN_FREQUENCY)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/KOLLENBE/Desktop/models\\001-words%d-sequence%d-minfreq%d-loss0.5259-acc0.7285-val_loss0.9796-val_acc0.6091(len(words), MIN_SEQ, MIN_FREQUENCY)\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001CFC6875B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001CFEFC70A30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 42s 88ms/step - loss: 0.5259 - accuracy: 0.7285 - val_loss: 0.9796 - val_accuracy: 0.6091\n",
      "Epoch 2/20\n",
      "443/443 [==============================] - 20s 45ms/step - loss: 0.4859 - accuracy: 0.7438 - val_loss: 1.0182 - val_accuracy: 0.6091\n",
      "Epoch 3/20\n",
      "443/443 [==============================] - 21s 46ms/step - loss: 0.4807 - accuracy: 0.7453 - val_loss: 1.0445 - val_accuracy: 0.5669\n",
      "Epoch 4/20\n",
      "443/443 [==============================] - 19s 44ms/step - loss: 0.4776 - accuracy: 0.7475 - val_loss: 1.0623 - val_accuracy: 0.6091\n",
      "Epoch 5/20\n",
      "443/443 [==============================] - 22s 50ms/step - loss: 0.4766 - accuracy: 0.7463 - val_loss: 1.0947 - val_accuracy: 0.5634\n",
      "Epoch 6/20\n",
      "441/443 [============================>.] - ETA: 0s - loss: 0.4749 - accuracy: 0.7484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/KOLLENBE/Desktop/models\\006-words%d-sequence%d-minfreq%d-loss0.4746-acc0.7485-val_loss1.1108-val_acc0.6302(len(words), MIN_SEQ, MIN_FREQUENCY)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/KOLLENBE/Desktop/models\\006-words%d-sequence%d-minfreq%d-loss0.4746-acc0.7485-val_loss1.1108-val_acc0.6302(len(words), MIN_SEQ, MIN_FREQUENCY)\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001CFC6875B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001CFEFC70A30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 40s 90ms/step - loss: 0.4746 - accuracy: 0.7485 - val_loss: 1.1108 - val_accuracy: 0.6302\n",
      "Epoch 7/20\n",
      "442/443 [============================>.] - ETA: 0s - loss: 0.4742 - accuracy: 0.7486"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/KOLLENBE/Desktop/models\\007-words%d-sequence%d-minfreq%d-loss0.4740-acc0.7487-val_loss1.1257-val_acc0.6796(len(words), MIN_SEQ, MIN_FREQUENCY)\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/KOLLENBE/Desktop/models\\007-words%d-sequence%d-minfreq%d-loss0.4740-acc0.7487-val_loss1.1257-val_acc0.6796(len(words), MIN_SEQ, MIN_FREQUENCY)\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001CFC6875B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001CFEFC70A30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 38s 85ms/step - loss: 0.4740 - accuracy: 0.7487 - val_loss: 1.1257 - val_accuracy: 0.6796\n",
      "Epoch 8/20\n",
      "443/443 [==============================] - 20s 46ms/step - loss: 0.4741 - accuracy: 0.7492 - val_loss: 1.1486 - val_accuracy: 0.6303\n",
      "Epoch 9/20\n",
      "234/443 [==============>...............] - ETA: 4s - loss: 0.4709 - accuracy: 0.7479"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [checkpoint, print_callback, early_stopping]\n\u001b[0;32m     17\u001b[0m examples_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_seqs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\keras\\engine\\training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3128\u001b[0m   (graph_function,\n\u001b[0;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m     args,\n\u001b[0;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1964\u001b[0m     executing_eagerly)\n\u001b[0;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Anaconda3-202205\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "#file_path = \"./checkpoints\\LSTM_LYRICS-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-loss{loss:.4f}-acc{accuracy:.4f}-val_loss{val_loss:.4f}-val_acc{val_accuracy:.4f}(len(words), MIN_SEQ, MIN_FREQUENCY)\"\n",
    "\n",
    "file_path = \"C:/Users/KOLLENBE/Desktop/models/{epoch:03d}-words%d-sequence%d-minfreq%d-loss{loss:.4f}-acc{accuracy:.4f}-val_loss{val_loss:.4f}-val_acc{val_accuracy:.4f}(len(words), MIN_SEQ, MIN_FREQUENCY)\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=20)\n",
    "\n",
    "callbacks_list = [checkpoint, print_callback, early_stopping]\n",
    "\n",
    "\n",
    "examples_file = open('examples.txt', \"w\")\n",
    "\n",
    "model.fit(generator(X_train, y_train, BATCH_SIZE),\n",
    "\n",
    "                   steps_per_epoch=int(len(valid_seqs)/BATCH_SIZE) + 1,\n",
    "\n",
    "                   epochs=20,\n",
    "\n",
    "                   callbacks=callbacks_list,\n",
    "\n",
    "                   validation_data=generator(X_test, y_train, BATCH_SIZE),\n",
    "\n",
    "                   validation_steps=int(len(y_train)/BATCH_SIZE) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43fb12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
